{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input,\n    Conv2D,\n    LeakyReLU,\n    Add,\n    BatchNormalization,\n    Dense,\n    GlobalAveragePooling2D,\n    Dropout\n)\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(images,labels) = ([],[])\nfolder = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n\nfor (subdirs, dirs, files) in os.walk(folder):\n    for subdir in dirs:\n        subjectpath = os.path.join(folder, subdir)\n        for filename in os.listdir(subjectpath):\n            path = subjectpath + '/' + filename\n            labels.append(subdir)\n            images.append(np.array(Image.open(path)))\n            break\nprint(len(images),len(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 10))\n\nfor i in range(15):\n    plt.subplot(2,15,i+1)\n    plt.imshow(images[i])\n    plt.title(labels[i])\n    plt.axis('off')\n    plt.grid('off')\n\nfor i in range(14):\n    plt.subplot(2,15,15+i+1)\n    plt.imshow(images[15+i])\n    plt.title(labels[i+15])\n    plt.axis('off')\n    plt.grid('off')\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(\n        rotation_range = 20,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        shear_range = 0.2,\n        validation_split = 0.2\n)\n\n\ntrain_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n\ntrain_data = train_gen.flow_from_directory(\n                train_dir,\n                target_size = (200,200),\n                batch_size = 32,\n                class_mode = 'categorical',\n                subset = 'training'\n)\n\nvalidation_dir = ''\nvalidation_data = train_gen.flow_from_directory(\n                train_dir,\n                target_size = (200,200),\n                batch_size = 32,\n                class_mode = 'categorical',\n                subset = 'validation'\n)\n\nclasses = list(train_data.class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DarknetConv(inputs, filters, kernel_size, strides):\n    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.1)(x)\n    \n    return x\n\ndef DarknetResidual(inputs, filters):\n    shortcut = inputs\n    x = DarknetConv(inputs, filters//2,kernel_size=(1,1),strides=(1,1))\n    x = DarknetConv(x, filters, kernel_size=(3,3),strides=(1,1))\n    x = Add()([x, shortcut])\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = Input(shape=(200,200,3))\nx = DarknetConv(inputs, 32, kernel_size=(3,3),strides=(1,1))\n\nx = DarknetConv(x, 64, kernel_size=(3,3), strides=(2,2))\n\nfor _ in range(1):\n    x = DarknetResidual(x, 64)\n    \nx = DarknetConv(x, 128, kernel_size=(3,3), strides=(2,2))\n\nfor _ in range(2):\n    x = DarknetResidual(x, 128)\n    \nx = DarknetConv(x, 256, kernel_size=(3,3), strides=(2,2))\n\nfor _ in range(8):\n    x = DarknetResidual(x, 256)\n    \nx = DarknetConv(x, 512, kernel_size=(3,3), strides=(2,2))\n\nfor _ in range(8):\n    x = DarknetResidual(x, 512)\n    \nx = DarknetConv(x, 1024, kernel_size=(3,3), strides=(2,2))\n\nfor _ in range(4):\n    x = DarknetResidual(x, 1024)\n    \nx = GlobalAveragePooling2D()(x)\n\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\n\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\n\n\noutput = Dense(29,activation='softmax')(x)\n\ndarknet = Model(inputs, output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"darknet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n    mode='auto', baseline=None, restore_best_weights=False\n)\n\n#early_stopping = EarlyStopping(\n #       monitor='val_loss',patience=5,\n#        min_delta = 0.001\n#)\n#reduce_lr = ReduceLROnPlateau(\n#        monitor='val_loss',patience=5\n#)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"darknet.compile(optimizer='adam', loss='categorical_crossentropy',\n               metrics=['acc'])\n\nhistory = darknet.fit_generator(train_data,\n                               epochs=10,\n                               validation_data=validation_data,\n                               callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#darknet.save_weights('asl_darknet.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['acc', 'val_acc']].plot();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = np.array(Image.open('../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/H_test.jpg'))\nsample_fed = np.expand_dims(sample, 0)\npred= darknet.predict(sample_fed)\npred = classes[np.argmax(pred)]\nplt.imshow(sample)\nplt.title(\"Actual: H, Predicted: {}\".format(pred))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = np.array(Image.open('../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/M_test.jpg'))\nsample_fed = np.expand_dims(sample, 0)\npred= darknet.predict(sample_fed)\npred = classes[np.argmax(pred)]\nplt.imshow(sample)\nplt.title(\"Actual:M, Predicted: {}\".format(pred))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}