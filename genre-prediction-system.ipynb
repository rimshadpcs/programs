{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import WordNetLemmatizer \nfrom copy import deepcopy\nfrom IPython.display import clear_output\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing dataset","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data[['title','genres','overview']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fortopicdf = data.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fortopicdf['overview']=fortopicdf['overview'].fillna('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fortopicdf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Having the first look at the data","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Genres Neat","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def make_it_neat(data,name):\n    arr=data[name].values\n    pp=[]\n    for i in arr:\n        x=i\n        x=x.replace('{','').replace('\"id\"','').replace('\"name\"','').replace('}','').replace('[','').replace(']','').replace(':','').replace('\"','')\n        p=[]\n        for i in x.split(','):\n            if i[2:].isdigit():\n                continue\n            else:\n                p.append(i[2:])\n        pp.append(p)\n    data[name]=pp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_it_neat(data,'genres')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['genres'].values[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Looks better right :)","metadata":{}},{"cell_type":"markdown","source":"# Let's lemmatize the description now","metadata":{}},{"cell_type":"code","source":"# Filling all the empty/nan description rows with empty string\ndata['overview']=data['overview'].fillna('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function is to remove stopwords from a particular column and to tokenize it\ndef rem_stopwords_tokenize(data,name):\n      \n    def getting(sen):\n        example_sent = sen\n\n        stop_words = set(stopwords.words('english')) \n\n        word_tokens = word_tokenize(example_sent) \n\n        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n\n        filtered_sentence = [] \n\n        for w in word_tokens: \n            if w not in stop_words: \n                filtered_sentence.append(w) \n        return filtered_sentence\n    x=[]\n    for i in data[name].values:\n        x.append(getting(i))\n    data[name]=x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rem_stopwords_tokenize(data,'overview')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making a function to lemmatize all the words\nlemmatizer = WordNetLemmatizer() \ndef lemmatize_all(data,name):\n    arr=data[name]\n    a=[]\n    for i in arr:\n        b=[]\n        for j in i:\n            x=lemmatizer.lemmatize(j,pos='a')\n            x=lemmatizer.lemmatize(x)\n            b.append(x)\n        a.append(b)\n    data[name]=a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lemmatize_all(data,'overview')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's have a look at the new updated data","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We need to vectorize genres and overview now ","metadata":{}},{"cell_type":"code","source":"dic_genres={}\ndic_overview={}\nfor i in data.genres:\n    for j in i:\n        if j not in dic_genres:\n            dic_genres[j]=0\n        else:\n            continue\nfor i in data.overview:\n    for j in i:\n        if j not in dic_overview:\n            dic_overview[j]=0\n        else:\n            continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's copy dataframe to new dataframe","metadata":{}},{"cell_type":"code","source":"df=deepcopy(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to convert word to vector","metadata":{}},{"cell_type":"code","source":"# This function is made to convert words to vector\ndef vectorizer(data,name,d):\n    arr=data[name].values\n    pp=[]\n    count=0\n    l=len(df)\n    for i in arr:\n        count+=1\n        clear_output(wait=True)\n        print('The progress is:','{:.2f}'.format(count*100/l),' %')\n        dic=deepcopy(d)\n        p=[]\n        for j in i:\n              dic[j]+=1\n        p=list(dic.values())\n        pp.append(p)\n    data[name]=pp\n            \n            \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer(df,'overview',dic_overview)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer(df,'genres',dic_genres)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic_overview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic_genres","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training model for genres predictions :)","metadata":{}},{"cell_type":"code","source":"X=df.overview.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=list(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df.genres.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=list(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ok guys since we have a lot of data we run out of ram :( ","metadata":{}},{"cell_type":"markdown","source":"## So we gonna work on smaller data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's try to predict the genre now :)","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=data[data['title']=='The Dark Knight Rises']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"over=x.overview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in list(over.values)[0]:\n    dic_overview[i]+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=list(dic_overview.values())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's predict the genre\nans=clf.predict([X])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans=list(list(ans)[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The genres for the movie The dark knight rises are:')\nprint()\nfor i in range(len(ans)):\n    if ans[i]==1:\n        print(list(dic_genres.keys())[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Top modeling","metadata":{}},{"cell_type":"code","source":"import gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"experimental code","metadata":{}},{"cell_type":"code","source":"movie = fortopicdf.loc[3]\ndisplay(movie)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overview = movie['overview']\nprint(overview)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.utils import simple_preprocess","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nstemmer = SnowballStemmer('english')\nnltk.download('wordnet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lemmatization\ndef lemmatize(text):\n    return WordNetLemmatizer().lemmatize(text, pos='v')\n\n\n# Stemming\ndef stemming(text):\n    return stemmer.stem(text)\n\n\n# Tokenization\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            LemmatizedToken = lemmatize(token)\n            result.append(stemming(LemmatizedToken))\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie = fortopicdf.loc[3]\ndisplay(movie)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overview = movie['overview']\nprint(overview)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(preprocess(overview))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"experiment ends here","metadata":{}},{"cell_type":"code","source":"processedMovies = fortopicdf['overview'].map(preprocess)\ndisplay(processedMovies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bag of words\n\ndictionary = gensim.corpora.Dictionary(processedMovies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary.filter_extremes(no_below=10, no_above=0.5,keep_n=100000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bowCorpus = [dictionary.doc2bow(doc) for doc in processedMovies]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(bowCorpus[3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim import corpora, models\ntfidf = models.TfidfModel(bowCorpus)\ntfidfCorpus = tfidf[bowCorpus]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(tfidfCorpus[3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom gensim.matutils import corpus2dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidfDense = corpus2dense(tfidfCorpus, num_terms=100000, num_docs=len(tfidfCorpus))\ntfidfDense = tfidfDense.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('movies, attributes:', tfidfDense.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fortopicdf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"denseMatrix, yCategory = [], []\nfor index, row in fortopicdf.iterrows():\n    for category in row['genres']:\n        denseMatrix.append(tfidfDense[index])\n        yCategory.append(category['name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}